<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Section 4 Independence and conditional probability | MATH1710 Probability and Statistics I</title>
  <meta name="description" content="Lecture notes for the course MATH1710 Probability and Statistics I at the University of Leeds, 2021–2022" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Section 4 Independence and conditional probability | MATH1710 Probability and Statistics I" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://mpaldridge.github.io/math1710/" />
  
  <meta property="og:description" content="Lecture notes for the course MATH1710 Probability and Statistics I at the University of Leeds, 2021–2022" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Section 4 Independence and conditional probability | MATH1710 Probability and Statistics I" />
  
  <meta name="twitter:description" content="Lecture notes for the course MATH1710 Probability and Statistics I at the University of Leeds, 2021–2022" />
  

<meta name="author" content="Matthew Aldridge" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="favicon.ico" type="image/x-icon" />
<link rel="prev" href="P2.html"/>
<link rel="next" href="P3.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">MATH1710 notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Schedule</a></li>
<li class="chapter" data-level="" data-path="about.html"><a href="about.html"><i class="fa fa-check"></i>About MATH1710</a>
<ul>
<li class="chapter" data-level="" data-path="about.html"><a href="about.html#organisation"><i class="fa fa-check"></i>Organisation of MATH1710</a>
<ul>
<li class="chapter" data-level="" data-path="about.html"><a href="about.html#notes"><i class="fa fa-check"></i>Notes and videos</a></li>
<li class="chapter" data-level="" data-path="about.html"><a href="about.html#problem-sheets"><i class="fa fa-check"></i>Problem sheets</a></li>
<li class="chapter" data-level="" data-path="about.html"><a href="about.html#lectures"><i class="fa fa-check"></i>Lectures</a></li>
<li class="chapter" data-level="" data-path="about.html"><a href="about.html#tutorials"><i class="fa fa-check"></i>Tutorials</a></li>
<li class="chapter" data-level="" data-path="about.html"><a href="about.html#r-worksheets"><i class="fa fa-check"></i>R worksheets</a></li>
<li class="chapter" data-level="" data-path="about.html"><a href="about.html#dropin"><i class="fa fa-check"></i>Optional “office hours” drop-in sessions</a></li>
<li class="chapter" data-level="" data-path="about.html"><a href="about.html#time"><i class="fa fa-check"></i>Time management</a></li>
<li class="chapter" data-level="" data-path="about.html"><a href="about.html#exam"><i class="fa fa-check"></i>Exam</a></li>
<li class="chapter" data-level="" data-path="about.html"><a href="about.html#ask"><i class="fa fa-check"></i>Who should I ask about…?</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="about.html"><a href="about.html#about-content"><i class="fa fa-check"></i>Content of MATH1710</a>
<ul>
<li class="chapter" data-level="" data-path="about.html"><a href="about.html#prereqs"><i class="fa fa-check"></i>Prerequisites</a></li>
<li class="chapter" data-level="" data-path="about.html"><a href="about.html#syllabus"><i class="fa fa-check"></i>Syllabus</a></li>
<li class="chapter" data-level="" data-path="about.html"><a href="about.html#books"><i class="fa fa-check"></i>Books</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="about.html"><a href="about.html#about-notes"><i class="fa fa-check"></i>About these notes</a></li>
</ul></li>
<li class="part"><span><b>Part I: EDA</b></span></li>
<li class="chapter" data-level="1" data-path="S01-eda.html"><a href="S01-eda.html"><i class="fa fa-check"></i><b>1</b> Exploratory data analysis</a>
<ul>
<li class="chapter" data-level="1.1" data-path="S01-eda.html"><a href="S01-eda.html#what-is-eda"><i class="fa fa-check"></i><b>1.1</b> What is EDA?</a></li>
<li class="chapter" data-level="1.2" data-path="S01-eda.html"><a href="S01-eda.html#what-is-R"><i class="fa fa-check"></i><b>1.2</b> What is R?</a></li>
<li class="chapter" data-level="1.3" data-path="S01-eda.html"><a href="S01-eda.html#summary-stat"><i class="fa fa-check"></i><b>1.3</b> Summary statistics and boxplots</a></li>
<li class="chapter" data-level="1.4" data-path="S01-eda.html"><a href="S01-eda.html#binned"><i class="fa fa-check"></i><b>1.4</b> Binned data and histograms</a></li>
<li class="chapter" data-level="1.5" data-path="S01-eda.html"><a href="S01-eda.html#multiple"><i class="fa fa-check"></i><b>1.5</b> Multiple variables and scatterplots</a></li>
<li class="chapter" data-level="" data-path="S01-eda.html"><a href="S01-eda.html#summary-01"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P1.html"><a href="P1.html"><i class="fa fa-check"></i>Problem Sheet 1</a>
<ul>
<li class="chapter" data-level="" data-path="P1.html"><a href="P1.html#P1-short"><i class="fa fa-check"></i>A: Short questions</a></li>
<li class="chapter" data-level="" data-path="P1.html"><a href="P1.html#P1-long"><i class="fa fa-check"></i>B: Long questions</a></li>
<li class="chapter" data-level="" data-path="P1.html"><a href="P1.html#P1-assessed"><i class="fa fa-check"></i>C: Assessed questions</a></li>
<li class="chapter" data-level="" data-path="P1.html"><a href="P1.html#P1-short-sols"><i class="fa fa-check"></i>Solutions to short questions</a></li>
</ul></li>
<li class="part"><span><b>Part II: Probability</b></span></li>
<li class="chapter" data-level="2" data-path="S02-probability.html"><a href="S02-probability.html"><i class="fa fa-check"></i><b>2</b> Probability spaces</a>
<ul>
<li class="chapter" data-level="2.1" data-path="S02-probability.html"><a href="S02-probability.html#what-is-prob"><i class="fa fa-check"></i><b>2.1</b> What is probability?</a></li>
<li class="chapter" data-level="2.2" data-path="S02-probability.html"><a href="S02-probability.html#sample-events"><i class="fa fa-check"></i><b>2.2</b> Sample spaces and events</a></li>
<li class="chapter" data-level="2.3" data-path="S02-probability.html"><a href="S02-probability.html#set-theory"><i class="fa fa-check"></i><b>2.3</b> Basic set theory</a></li>
<li class="chapter" data-level="2.4" data-path="S02-probability.html"><a href="S02-probability.html#axioms"><i class="fa fa-check"></i><b>2.4</b> Probability axioms</a></li>
<li class="chapter" data-level="2.5" data-path="S02-probability.html"><a href="S02-probability.html#prob-properties"><i class="fa fa-check"></i><b>2.5</b> Properties of probability</a></li>
<li class="chapter" data-level="2.6" data-path="S02-probability.html"><a href="S02-probability.html#addition"><i class="fa fa-check"></i><b>2.6</b> Addition rules for unions</a></li>
<li class="chapter" data-level="" data-path="S02-probability.html"><a href="S02-probability.html#summary-02"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="S03-classical.html"><a href="S03-classical.html"><i class="fa fa-check"></i><b>3</b> Classical probability</a>
<ul>
<li class="chapter" data-level="3.1" data-path="S03-classical.html"><a href="S03-classical.html#classical-intro"><i class="fa fa-check"></i><b>3.1</b> Probability with equally likely outcomes</a></li>
<li class="chapter" data-level="3.2" data-path="S03-classical.html"><a href="S03-classical.html#multiplication"><i class="fa fa-check"></i><b>3.2</b> Multiplication principle</a></li>
<li class="chapter" data-level="3.3" data-path="S03-classical.html"><a href="S03-classical.html#sampling"><i class="fa fa-check"></i><b>3.3</b> Sampling with and without replacement</a></li>
<li class="chapter" data-level="3.4" data-path="S03-classical.html"><a href="S03-classical.html#ordering"><i class="fa fa-check"></i><b>3.4</b> Ordering</a></li>
<li class="chapter" data-level="3.5" data-path="S03-classical.html"><a href="S03-classical.html#combinations"><i class="fa fa-check"></i><b>3.5</b> Sampling without replacement in any order</a></li>
<li class="chapter" data-level="3.6" data-path="S03-classical.html"><a href="S03-classical.html#birthday"><i class="fa fa-check"></i><b>3.6</b> Birthday problem</a></li>
<li class="chapter" data-level="" data-path="S03-classical.html"><a href="S03-classical.html#summary-03"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P2.html"><a href="P2.html"><i class="fa fa-check"></i>Problem Sheet 2</a>
<ul>
<li class="chapter" data-level="" data-path="P2.html"><a href="P2.html#P2-short"><i class="fa fa-check"></i>A: Short questions</a></li>
<li class="chapter" data-level="" data-path="P2.html"><a href="P2.html#P2-long"><i class="fa fa-check"></i>B: Long questions</a></li>
<li class="chapter" data-level="" data-path="P2.html"><a href="P2.html#P2-assessed"><i class="fa fa-check"></i>C: Assessed questions</a></li>
<li class="chapter" data-level="" data-path="P2.html"><a href="P2.html#P2-short-sols"><i class="fa fa-check"></i>Solutions to short questions</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="S04-conditional.html"><a href="S04-conditional.html"><i class="fa fa-check"></i><b>4</b> Independence and conditional probability</a>
<ul>
<li class="chapter" data-level="4.1" data-path="S04-conditional.html"><a href="S04-conditional.html#independent-events"><i class="fa fa-check"></i><b>4.1</b> Independent events</a></li>
<li class="chapter" data-level="4.2" data-path="S04-conditional.html"><a href="S04-conditional.html#conditional"><i class="fa fa-check"></i><b>4.2</b> Conditional probability</a></li>
<li class="chapter" data-level="4.3" data-path="S04-conditional.html"><a href="S04-conditional.html#chain-rule"><i class="fa fa-check"></i><b>4.3</b> Chain rule</a></li>
<li class="chapter" data-level="4.4" data-path="S04-conditional.html"><a href="S04-conditional.html#total-prob"><i class="fa fa-check"></i><b>4.4</b> Law of total probability</a></li>
<li class="chapter" data-level="4.5" data-path="S04-conditional.html"><a href="S04-conditional.html#bayes"><i class="fa fa-check"></i><b>4.5</b> Bayes’ theorem</a></li>
<li class="chapter" data-level="4.6" data-path="S04-conditional.html"><a href="S04-conditional.html#screening"><i class="fa fa-check"></i><b>4.6</b> Diagnostic testing</a></li>
<li class="chapter" data-level="" data-path="S04-conditional.html"><a href="S04-conditional.html#summary-034"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="P3.html"><a href="P3.html"><i class="fa fa-check"></i>Problem Sheet 3</a>
<ul>
<li class="chapter" data-level="" data-path="P3.html"><a href="P3.html#P3-short"><i class="fa fa-check"></i>A: Short questions</a></li>
<li class="chapter" data-level="" data-path="P3.html"><a href="P3.html#P3-long"><i class="fa fa-check"></i>B: Long questions</a></li>
<li class="chapter" data-level="" data-path="P3.html"><a href="P3.html#P3-assessed"><i class="fa fa-check"></i>C: Assessed questions</a></li>
<li class="chapter" data-level="" data-path="P3.html"><a href="P3.html#P3-short-sols"><i class="fa fa-check"></i>Solutions to short questions</a></li>
</ul></li>
<li class="part"><span><b>Other stuff</b></span></li>
<li class="chapter" data-level="" data-path="R.html"><a href="R.html"><i class="fa fa-check"></i>R Worksheets</a>
<ul>
<li class="chapter" data-level="" data-path="R.html"><a href="R.html#r-work"><i class="fa fa-check"></i>R worksheets</a></li>
<li class="chapter" data-level="" data-path="R.html"><a href="R.html#about-r"><i class="fa fa-check"></i>About R and RStudio</a></li>
<li class="chapter" data-level="" data-path="R.html"><a href="R.html#r-access"><i class="fa fa-check"></i>How to access R and RStudio</a></li>
<li class="chapter" data-level="" data-path="R.html"><a href="R.html#r-install"><i class="fa fa-check"></i>Installing R and RStudio</a></li>
<li class="chapter" data-level="" data-path="R.html"><a href="R.html#troubleshooting"><i class="fa fa-check"></i>Troubleshooting drop-in sessions</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="solutions.html"><a href="solutions.html"><i class="fa fa-check"></i>Solutions and group feedback</a>
<ul>
<li class="chapter" data-level="" data-path="solutions.html"><a href="solutions.html#P1-solutions"><i class="fa fa-check"></i>Problem Sheet 1</a></li>
</ul></li>
<li class="divider"></li>
<li></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">MATH1710 Probability and Statistics I</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="S04-conditional" class="section level1" number="4">
<h1><span class="header-section-number">Section 4</span> Independence and conditional probability</h1>
<div id="independent-events" class="section level2" number="4.1">
<h2><span class="header-section-number">4.1</span> Independent events</h2>
<div class="videowrap">
<div class="videowrapper">
<iframe src="https://www.youtube.com/embed/9lhF4WEoJxk">
</iframe>
</div>
</div>
<p><em>Suppose 40% of people have blond hair, and 20% of people have blue eyes. What proportion of people have both blond hair and blue eyes?</em></p>
<p>The answer to this question is: we don’t know. The question doesn’t give us enough information to tell. However, <em>if</em> it were the case that having blond hair didn’t effect your chance of having blue eyes, then we could work out the answer. If that were true, we would think that the 20% of people with blue eyes equally made up both 20% of the blonds and also 20% of the non-blonds. Thus the proportion of people with blond hair and blue eyes would be this 20% of the 40% of people with blond hair, and 20% of 40% is <span class="math inline">\(0.2 \times 0.4 = 0.08\)</span>, or 8%.</p>
<p>To put it in probability language, <em>if</em> blond hair and blue eyes were unrelated, then we would expect that
<span class="math display">\[ \mathbb P(\text{blond hair and blue eyes}) = \mathbb P(\text{blond hair}) \times \mathbb P(\text{blue eyes}) . \]</span>
This is an important property known as “independence”.</p>
<div class="definition">
<p><span id="def:unlabeled-div-31" class="definition"><strong>Definition 4.1  </strong></span>Two events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are said to be <strong>independent</strong> if
<span class="math display">\[ \mathbb P(A \cap B) = \mathbb P(A)\, \mathbb P(B) .  \]</span></p>
</div>
<p>There are two ways we can use this definition.</p>
<ul>
<li>If we know <span class="math inline">\(\mathbb P(A)\)</span>, <span class="math inline">\(\mathbb P(B)\)</span>, and <span class="math inline">\(\mathbb P(A \cap B)\)</span>, then we can find out whether or not <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are independent by checking whether or not <span class="math inline">\(\mathbb P(A \cap B) = \mathbb P(A)\, \mathbb P(B)\)</span>.</li>
<li>If we know <span class="math inline">\(\mathbb P(A)\)</span> and <span class="math inline">\(\mathbb P(B)\)</span> and we know that <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are independent, then we can find <span class="math inline">\(\mathbb P(A \cap B)\)</span> by calculating <span class="math inline">\(\mathbb P(A \cap B) = \mathbb P(A)\, \mathbb P(B)\)</span>.</li>
</ul>
<p>In this second case, we might know <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are independent because we are specifically told they are. But we might reason that <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> because the related experiments are not physically related – for example if we roll a dice then toss a coin, we might reason that <span class="math inline">\(\{\text{roll a 5}\}\)</span> and <span class="math inline">\(\{\text{the coin lands Heads}\}\)</span> must be independent because the dice roll doesn’t effect the coin toss, and use the independence assumption in calculations.</p>
<div class="example">
<p><span id="exm:unlabeled-div-32" class="example"><strong>Example 4.1  </strong></span><em>Consider rolling a dice. Let <span class="math inline">\(A = \{\text{even number}\} = \{2,4,6\}\)</span>, and let <span class="math inline">\(B = \{\text{roll at least 4}\} = \{4,5,6\}\)</span>. Are <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> independent?</em></p>
<p>Clearly we have <span class="math inline">\(\mathbb P(A) = \frac36 = \frac12\)</span> and <span class="math inline">\(\mathbb P(B) = \frac 36 = \frac12\)</span>. The intersection is <span class="math inline">\(A \cap B = \{4,6\}\)</span>, so <span class="math inline">\(\mathbb P(A \cap B) = \frac26 = \frac13\)</span>. So we see that
<span class="math display">\[ \mathbb P(A\cap B) = \frac13  \qquad \text{and} \qquad  \mathbb P(A)\, \mathbb P(B) = \frac12 \times \frac12 = \frac14 . \]</span>
So <span class="math inline">\(\mathbb P(A \cap B) \neq \mathbb P(A)\, \mathbb P(B)\)</span>, and the two events are not independent.</p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-33" class="example"><strong>Example 4.2  </strong></span><em>A biased coin has probability <span class="math inline">\(p\)</span> of landing Heads and probability <span class="math inline">\(1-p\)</span> of landing Tails. You toss the coin 3 times. Assuming tosses of the coin are independent, calculate the probability of getting exactly 2 Heads.</em></p>
<p>There are three ways we could get exactly 2 Heads: HHT, HTH, or THH. For the first of these,
<span class="math display">\[ \mathbb P(\text{HHT}) = \mathbb P(\text{first coin H} \cap \text{second coin H} \cap \text{third coin T}) . \]</span>
Since tosses of the coin are independent, we therefore have
<span class="math display">\[\begin{align*}
\mathbb P(\text{HHT})
  &amp;= \mathbb P(\text{first coin H}) \times \mathbb P ( \text{second coin H} )\times \mathbb P(\text{third coin T}) \\
  &amp;=p \times p \times (1-p) \\
  &amp;= p^2(1-p).
\end{align*}\]</span></p>
<p>Similarly,
<span class="math display">\[ \mathbb P(\text{HTH}) = \mathbb P(\text{THH}) = p^2(1-p) \]</span>
also.</p>
<p>Finally, because the events are disjoint, we have
<span class="math display">\[ \mathbb P(\text{HHT} \cup\text{HTH} \cup \text{THH}) = \mathbb P(\text{HHT} ) + \mathbb P(\text{HTH}) + \mathbb P(\text{THH}) = 3p^2(1-p) . \]</span></p>
</div>
</div>
<div id="conditional" class="section level2" number="4.2">
<h2><span class="header-section-number">4.2</span> Conditional probability</h2>
<div class="videowrap">
<div class="videowrapper">
<iframe src="https://www.youtube.com/embed/x3wISv0RWic">
</iframe>
</div>
</div>
<p>Let us to return to the example of blond hair and blue eyes. Suppose the population statistics are like this:</p>
<table>
<thead>
<tr class="header">
<th align="center"></th>
<th align="center"><strong>Brown hair</strong></th>
<th align="center"><strong>Blond hair</strong></th>
<th align="center"><strong>Total</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>Brown eyes</strong></td>
<td align="center">50%</td>
<td align="center">30%</td>
<td align="center">80%</td>
</tr>
<tr class="even">
<td align="center"><strong>Blue eyes</strong></td>
<td align="center">10%</td>
<td align="center">10%</td>
<td align="center">20%</td>
</tr>
<tr class="odd">
<td align="center"><strong>Total</strong></td>
<td align="center">60%</td>
<td align="center">40%</td>
<td align="center">100%</td>
</tr>
</tbody>
</table>
<p>(It turns out that <span class="math inline">\(\mathbb P(\text{blond hair and blue eyes}) = 0.1 \neq 0.08\)</span>, so they are not independent.)</p>
<p>We know that 20% of people have blue eyes. But suppose you already know that someone has blond hair: what then is their probability of have blue eyes <em>given</em> that they have blond hair?</p>
<p>Well, the 24% of blond-haired people is made up of the 10% of people who also have blue eyes to go along with their blond hair, and the 30% of people who have brown eyes to go along with their blond hair. So of the 40% of blond-haired people, three times as many have brown eyes, so only one quarter of that 40% have blue eyes. If we use a vertical line <span class="math inline">\(|\)</span> in a probability to mean “given” (or “assuming that” or “conditional upon”), then we can write this as
<span class="math display">\[  \mathbb P(\text{blue eyes} \mid \text{blond hair}) = \frac{\mathbb P(\text{blue eyes and blond hair})}{\mathbb P(\text{blond hair})} = \frac{0.1}{0.4} = \frac14. \]</span></p>
<p>What we’ve seen here is called a “conditional probability”.</p>
<div class="definition">
<p><span id="def:unlabeled-div-34" class="definition"><strong>Definition 4.2  </strong></span>Let <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> be events, with <span class="math inline">\(\mathbb P(A) &gt; 0\)</span>. Then the <strong>conditional probability of <span class="math inline">\(B\)</span> given <span class="math inline">\(A\)</span></strong> is defined to be
<span class="math display">\[  \mathbb P(B \mid A) = \frac{\mathbb P(A \cap B)}{\mathbb P(A)} . \]</span></p>
</div>
<p>The condition <span class="math inline">\(\mathbb P(A) &gt; 0\)</span> is to ensure we don’t have any “divide by 0” errors. (I normally won’t bother saying this explicitly – any statement about conditional probability will implicitly assume that the event being conditioned on has nonzero probability.)</p>
<p>As with independence, conditional probability can be used in different ways: given any two of <span class="math inline">\(\mathbb P(A)\)</span>, <span class="math inline">\(\mathbb P(A \cap B)\)</span>, and <span class="math inline">\(\mathbb P(B \mid A)\)</span> you can work out the other one.</p>
<p>Conditional probability ties in with independence in an important way. Suppose <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are independent, so <span class="math inline">\(\mathbb P(A \cap B) = \mathbb P(A) \, \mathbb P(B)\)</span>. Then the conditional probability becomes
<span class="math display">\[ \mathbb P(B \mid A) = \mathbb P(B \mid A) = \frac{\mathbb P(A \cap B)}{\mathbb P(A)} =  \frac{\mathbb P(A) \, \mathbb P(B)}{\mathbb P(A)} = \mathbb P(B) , \]</span>
so <span class="math inline">\(\mathbb P(B \mid A) = \mathbb P(B)\)</span>. In other words, if <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are independent, then <span class="math inline">\(A\)</span> happening doesn’t affect the probability of <span class="math inline">\(B\)</span> happening (and vice versa).</p>
<p>So when we have independence, <span class="math inline">\(\mathbb P(A \cap B) = \mathbb P(A)\,\mathbb P(B)\)</span>, and the mathematics is quite easy. But conditional probability tells us how things work when we don’t have independence.</p>
</div>
<div id="chain-rule" class="section level2" number="4.3">
<h2><span class="header-section-number">4.3</span> Chain rule</h2>
<p>We can rewrite the definition of conditional probability like this:
<span class="math display">\[ \mathbb P(A \cap B) = \mathbb P(A)\, \mathbb P(B \mid A). \]</span>
This can be a useful way to think when <span class="math inline">\(A\)</span> concerns the first stage of an experiment and <span class="math inline">\(B\)</span> the second stage. This says that the probability <span class="math inline">\(A\)</span> happens then <span class="math inline">\(B\)</span> happens is equal to the probability <span class="math inline">\(A\)</span> happens multiplied the probability, given that <span class="math inline">\(A\)</span> has happened, that <span class="math inline">\(B\)</span> then happens too.</p>
<p>We can extend this to more events. For three events, we have
<span class="math display">\[\begin{align*}
\mathbb P(A \cap B \cap C)
  &amp;= \mathbb P(A \cap B) \, \mathbb P(C \mid A \cap B) \\
  &amp;= \mathbb P(A) \, \mathbb P(B \mid A)\, \mathbb P(C \mid A \cap B) ,
\end{align*}\]</span>
which can be useful when we have three stages of an experiment.</p>
<p>Continuing that process, we get a general rule.</p>
<div class="theorem">
<p><span id="thm:thchain" class="theorem"><strong>Theorem 4.1  (Chain rule) </strong></span>For events <span class="math inline">\(A_1, A_2, \dots, A_n\)</span>, we have
<span class="math display">\[\begin{multline*}  \mathbb P(A_1 \cap A_2 \cap \cdots \cap A_n) \\
  = \mathbb P(A_1) \, \mathbb P(A_2 \mid A_1) \, \mathbb P(A_3 \mid A_1 \cap A_2) \cdots \mathbb P(A_n \mid A_1 \cap A_2 \cap \cdots \cap  A_n) .\end{multline*}\]</span></p>
</div>
<p>Often questions that can be solved using the classical probability counting methods from Section 3 also be solved in stages using the chain rule. (It’s a matter of personal taste which you prefer.)</p>
<div class="example">
<p><span id="exm:unlabeled-div-35" class="example"><strong>Example 4.3  </strong></span><em>Recall the Lotto problem from Example <a href="S03-classical.html#exm:lotto">3.6</a>: What is the probability we match 6 balls from 59?</em></p>
<p>Let <span class="math inline">\(A_1, A_2, \dots, A_6\)</span> be the events that the first, second, …, sixth balls out of the machine are on our ticket. Clearly <span class="math inline">\(\mathbb P(A_1) = \frac{6}{59}\)</span>, as we have six numbers the ball could match. Then the conditional probability that the second ball matches given that the first ball matched is <span class="math inline">\(\mathbb P(A_2 \mid A_1) = \frac{5}{58}\)</span>, because there are 58 balls left in the machine and, given that we got the first number right, there are 5 numbers left on our ticket. Similarly, <span class="math inline">\(\mathbb P(A_3 \mid A_1 \cap A_2) = \frac{4}{57}\)</span>, and so on, down to <span class="math inline">\(\mathbb P(A_6 \mid A_1 \cap \cdots\cap A_5) = \frac{1}{54}\)</span>.</p>
<p>So, using the chain rule, we get
<span class="math display">\[\begin{align*}
\mathbb P(A_1 \cap A_2 &amp;\cap \cdots \cap A_6) \\
&amp;= \mathbb P(A_1) \, \mathbb P(A_2 \mid A_1) \, \mathbb P(A_3 \mid A_1 \cap A_2) \cdots \mathbb P(A_6 \mid A_1 \cap \cdots \cap A_5) \\
&amp;= \frac{6}{59} \times \frac{5}{58} \times \frac{4}{57} \times \frac{3}{56} \times \frac{2}{55} \times \frac{1}{54} .
\end{align*}\]</span></p>
<p>The answer we got before was
<span class="math display">\[ \frac{6 \times 5 \times 4 \times 3 \times 2 \times 1}{59 \times 58 \times 57 \times 56 \times 55 \times 54} . \]</span>
It’s easy to see that this is the same answer, and the structure of the answers shows how the old method got the answer “all at once”, while this new method gets the answer “one stage at a time”.</p>
</div>
</div>
<div id="total-prob" class="section level2" number="4.4">
<h2><span class="header-section-number">4.4</span> Law of total probability</h2>
<div class="videowrap">
<div class="videowrapper">
<iframe src="https://www.youtube.com/embed/zBfFOYkfoss">
</iframe>
</div>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-36" class="example"><strong>Example 4.4  </strong></span><em>My friend has three dice: a 4-sided dice, a 6-side dice, and a 10-side dice. He picks one of them at random, with each dice equally likely. What is the probability my friend rolls a 5?</em></p>
<p>If my friend were to tell which dice he picked, then this question would be very easy! If we write <span class="math inline">\(D_4\)</span>, <span class="math inline">\(D_6\)</span> and <span class="math inline">\(D_{10}\)</span> to be the events that he picks the 4-sided, 6-sided, or 10-sided dice, then we know immediately that
<span class="math display">\[ \mathbb P(\text{roll 4} \mid D_4) = 0 \qquad \mathbb P(\text{roll 4} \mid D_6) = \tfrac16 \qquad \mathbb P(\text{roll 4} \mid D_{10}) = \tfrac{1}{10} .  \]</span>
What we need is a way to combine the results for different “sub-cases” into an over-all answer.</p>
</div>
<p>Luckily, there exists just such a tool for this job! It’s called the “law of total probability” (also known as the “partition theorem”). The important point is to make sure that the different sub-cases cover all possibilities, but that only one of them happens at a time.</p>
<div class="definition">
<p><span id="def:unlabeled-div-37" class="definition"><strong>Definition 4.3  </strong></span>A set of events <span class="math inline">\(A_1, A_2, \dots, A_n\)</span> are said to be a <strong>partition</strong> of the sample space <span class="math inline">\(\Omega\)</span> if</p>
<ol style="list-style-type: decimal">
<li>they are disjoint, in that <span class="math inline">\(A_i \cap A_j = \varnothing\)</span> for all <span class="math inline">\(i \neq j\)</span>;</li>
<li>they cover space, in that <span class="math inline">\(A_1 \cup A_2 \cup \cdots \cup A_n = \Omega\)</span>.</li>
</ol>
</div>
<div class="theorem">
<p><span id="thm:thlawtotal" class="theorem"><strong>Theorem 4.2  (Law of total probability) </strong></span>Let <span class="math inline">\(A_1, A_2, \dots, A_n\)</span> be a partition, and <span class="math inline">\(B\)</span> another event. Then
<span class="math display">\[ \mathbb P(B) = \sum_{i=1}^n \mathbb P(A_i) \, \mathbb P(B \mid A_i) . \]</span></p>
</div>
<p>So the law of total probability tells us we can add up the probabilities <span class="math inline">\(\mathbb P(B \mid A_i)\)</span> for each of the sub-cases provided we weight them by how likely <span class="math inline">\(\mathbb P(A_i)\)</span> by how likely each sub-case is.</p>
<div class="proof">
<p><span id="unlabeled-div-38" class="proof"><em>Proof</em>. </span>Since the partition of <span class="math inline">\(A_i\)</span>s cover space, we can split up <span class="math inline">\(B\)</span> depending on which part of the partition it is in:
<span class="math display">\[  B = (B \cap A_1) \cup (B \cap A_2) \cup \cdots \cup (B \cap A_n) .  \]</span></p>
<p><em>[I meant to draw a picture here, but didn’t get round to it – perhaps you’d like to draw your own?]</em></p>
<p>Since the <span class="math inline">\(A_i\)</span> are disjoint, the union on the right is disjoint also.
Therefore we can use Axiom 3 to get
<span class="math display">\[ \mathbb P(B) = \sum_{i=1}^n \mathbb P(B \cap A_i) . \]</span>
But using the definition of conditional probability, each “summand” (term inside the sum) is
<span class="math display">\[ \mathbb P(B \cap A_i) = \mathbb P(A_i) \, \mathbb P(B \mid A_i) . \]</span>
The result follows.</p>
</div>
<p>Returning to our dice example, <span class="math inline">\(D_4, D_6, D_{10}\)</span> is indeed a partition, since these are the only possibilities and we only choose one dice. So the law of total probability tells us that
<span class="math display">\[ \mathbb P(\text{roll 5}) = \mathbb P(D_4) \, \mathbb P(\text{roll 5} \mid D_4) +  \mathbb P(D_6) \, \mathbb P(\text{roll 5} \mid D_6) + \mathbb P(D_{10}) \, \mathbb P(\text{roll 5} \mid D_{10}) . \]</span></p>
<p>We were told that all the dice were picked with equal probability, so <span class="math inline">\(\mathbb P(D_4) = \mathbb P(D_6) = \mathbb P(D_{10}) = \frac13\)</span>, and we calculated the individual conditional probabilities as
<span class="math display">\[ \mathbb P(\text{roll 4} \mid D_4) = 0 \qquad \mathbb P(\text{roll 4} \mid D_6) = \tfrac16 \qquad \mathbb P(\text{roll 4} \mid D_{10}) = \tfrac{1}{10} .  \]</span></p>
<p>Therefore, we have
<span class="math display">\[ \mathbb P(\text{roll 5}) = \tfrac13\times 0 +  \tfrac13\times\tfrac16 +  \tfrac13\times\tfrac1{10} = \tfrac{8}{90} = 0.089. \]</span></p>
</div>
<div id="bayes" class="section level2" number="4.5">
<h2><span class="header-section-number">4.5</span> Bayes’ theorem</h2>
<div class="videowrap">
<div class="videowrapper">
<iframe src="https://www.youtube.com/embed/uLSewGUPH1g">
</iframe>
</div>
</div>
<p>In this subsection, we will discuss an important result called <strong>Bayes’ theorem</strong>.
Let’s first state and prove this result, and do an example, and then afterwards we’ll talk about two reasons why Bayes’ theorem is so important.</p>
<div class="theorem">
<p><span id="thm:thbayes" class="theorem"><strong>Theorem 4.3  (Bayes' theorem) </strong></span>For events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> with <span class="math inline">\(\mathbb P(A), \mathbb P(B) &gt; 0\)</span>, we have
<span class="math display">\[ \mathbb P(A \mid B) = \frac{\mathbb P(A) \,\mathbb P(B \mid A)}{\mathbb P(B)} .  \]</span></p>
</div>
<p>Bayes’ theorem is thought to have first appeared in the writings of Rev. <a href="https://mathshistory.st-andrews.ac.uk/Biographies/Bayes/">Thomas Bayes</a>, a British church minister and mathematician, shortly after his death, in the 1760s. However, his work was significantly edited by <a href="https://mathshistory.st-andrews.ac.uk/Biographies/Price/">Richard Price</a>, another minister–mathematician, and many people think that Price deserves a large share of the credit.</p>
<div class="proof">
<p><span id="unlabeled-div-39" class="proof"><em>Proof</em>. </span>From the definition of conditional probability, we can write <span class="math inline">\(\mathbb P(A \cap B)\)</span> in two different ways: we can write it as
<span class="math display">\[  \mathbb P(A \cap B) = \mathbb P(A) \, \mathbb P(B\mid A) , \]</span>
but we can also write it as
<span class="math display">\[  \mathbb P(A \cap B) = \mathbb P(B) \, \mathbb P(A\mid B) . \]</span>
Since these are two different ways of writing the same thing, we can equate them, to get
<span class="math display">\[ \mathbb P(A) \, \mathbb P(B\mid A) = \mathbb P(B) \, \mathbb P(A\mid B) . \]</span>
Dividing both sides by <span class="math inline">\(\mathbb P(B)\)</span> gives the result.</p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-40" class="example"><strong>Example 4.5  </strong></span><em>My friend again secretly picks the 4-sided, 6-sided, or 10-sided dice, each with probability <span class="math inline">\(\frac13\)</span>. He rolls that secret dice, and tells me he rolled a 5. What is the probability he picked the 6-sided dice?</em></p>
<p>This is asking us to calculate <span class="math inline">\(\mathbb P(D_6 \mid \text{roll 5})\)</span>. Bayes’ theorem tells us that
<span class="math display">\[
  \mathbb P(D_6 \mid \text{roll 5})
  = \frac{\mathbb P(D_6) \, \mathbb P(\text{roll 5} \mid D_6)}{\mathbb P(\text{roll 5})} 
  = \frac{\frac13 \times \frac16}{\frac{8}{90}} 
  = \tfrac{5}{8} ,
\]</span>
since we had calculated <span class="math inline">\(\mathbb P(\text{roll 5}) = \frac{8}{90}\)</span> in the previous subsection.</p>
</div>
<p>The first way to think about Bayes’ theorem is that it tells us how to relate <span class="math inline">\(\mathbb P(A \mid B)\)</span> and <span class="math inline">\(\mathbb P(B \mid A)\)</span>. Remember that <span class="math inline">\(\mathbb P(A \mid B)\)</span> and <span class="math inline">\(\mathbb P(B \mid A)\)</span> are not the same thing! The conditional probability someone is under 40 given they are a Premiership footballer is very high, but the conditional probability someone is a Premiership footballer given they are under 40 is very low.</p>
<p>Bayes’ theorem, in this first view, is a useful technical result that helps us switch the order of a conditional probability from <span class="math inline">\(B\)</span> given <span class="math inline">\(A\)</span> to <span class="math inline">\(A\)</span> given <span class="math inline">\(B\)</span>: we have
<span class="math display">\[ \mathbb P(A \mid B) = \frac{\mathbb P(A)}{\mathbb P(B)} \times \mathbb P(B \mid A) .  \]</span></p>
<p>In the dice example, the probability <span class="math inline">\(\mathbb P(\text{roll 5} \mid D_6) = \frac16\)</span> was very obvious, but Bayes’ theorem allowed us to reverse the conditioning, to find <span class="math inline">\(\mathbb P(D_6 \mid \text{roll 5}) = \frac58\)</span> instead.</p>
<p>The second way to think about Bayes’ rule is that it tells us how to update our beliefs as we acquire more evidence. That is, we might start by believing that the probability some event <span class="math inline">\(A\)</span> will occur is <span class="math inline">\(\mathbb P(A)\)</span>. But then we find out that <span class="math inline">\(B\)</span> has occurred, so we want to incorporate that knowledge and update our belief of the probability <span class="math inline">\(A\)</span> will occur to <span class="math inline">\(\mathbb P(A \mid B)\)</span>, the conditional probability <span class="math inline">\(A\)</span> will occur given this new evidence <span class="math inline">\(B\)</span>.</p>
<p>Bayes theorem, in this second view, tells us how to update from <span class="math inline">\(\mathbb P(A)\)</span> to <span class="math inline">\(\mathbb P(A \mid B)\)</span>: we have
<span class="math display">\[ \mathbb P(A \mid B) = \mathbb P(A) \times \frac{\mathbb P(B \mid A)}{\mathbb P(B)} .  \]</span></p>
<p>In the dice example, we initially believed there was a <span class="math inline">\(\mathbb P(D_6) = \frac13 = 0.333\)</span> chance our friend had chosen the six-sided dice. But when we heard that our friend had rolled a 5, we updated our belief to now thinking there was now a <span class="math inline">\(\mathbb P(D_6 \mid \text{roll 5}) =\frac58 = 0.625\)</span> chance it was the 6-sided dice.</p>
<p>This second way of thinking about Bayes’ theorem is at the heart of <strong>Bayesian statistics</strong>. In Bayesian statistics, we start with a “prior” belief about a model, then, after collecting some data, we update to a “posterior” belief, according to the rules of Bayes’ theorem. We will discuss Bayesian statistics much more in Section 10.</p>
<p>Quite often we use Bayes’ theorem and the law of total probability together. If we have a partition <span class="math inline">\(A_1, A_2, \dots, A_n\)</span>, perhaps representing some possible hypotheses, and we observe an event <span class="math inline">\(B\)</span>, then Bayes’ theorem tells us how likely each hypothesis is given the observation:
<span class="math display">\[ \mathbb P(A_i \mid B) = \frac{\mathbb P(A_i) \,\mathbb P(B \mid A_i)}{\mathbb P(B)} .  \]</span>
But this shared denominator <span class="math inline">\(\mathbb P(B)\)</span> can be expanded using the law of total probability
<span class="math display">\[ \mathbb P(B) = \sum_{j=1}^n \mathbb P(A_j) \,\mathbb P(B \mid A_j) . \]</span>
Together, we get the following.</p>
<div class="theorem">
<p><span id="thm:bayes-total" class="theorem"><strong>Theorem 4.4  </strong></span>Let <span class="math inline">\(\{A_1, A_2, \dots, A_n\}\)</span> be a partition of a sample space and let <span class="math inline">\(B\)</span> be another event. Then, for all <span class="math inline">\(i=1,2,\dots,n\)</span>, we have
<span class="math display">\[ \mathbb P(A_i \mid B) = \frac{\mathbb P(A_i) \,\mathbb P(B \mid A_i)}{\sum_{j=1}^n \mathbb P(A_j) \, \mathbb P(B \mid A_j)} .  \]</span></p>
</div>
<p>This is essentially what we did with the dice example, although we split it up into two separate parts rather than using this formula directly.</p>
</div>
<div id="screening" class="section level2" number="4.6">
<h2><span class="header-section-number">4.6</span> Diagnostic testing</h2>
<p><em>Members of the public are tested for a certain disease. About 2% of the population have the disease. The test is 95% accurate, in the following sense: if you have the disease, there’s a 95% chance you correctly get a positive test result, while if you don’t have the disease, there’s a 95% chance you correctly get a negative test result. Suppose you get a positive test result. What is the probability you have the disease?</em></p>
<p>The first thing we have to do is translate the words in the question into probability statements. Let <span class="math inline">\(D\)</span> be the event you have the disease, so <span class="math inline">\(D^\mathsf{c}\)</span> is the event you don’t have the disease, and let <span class="math inline">\(+\)</span> be the event you get a positive result. Then the question tells us that</p>
<ul>
<li><span class="math inline">\(\mathbb P(D) = 0.02\)</span> and <span class="math inline">\(\mathbb P(D^\mathsf{c}) = 0.98\)</span>;</li>
<li><span class="math inline">\(\mathbb P({+} \mid D) = 0.95\)</span> and <span class="math inline">\(\mathbb P({+}\mid D^\mathsf{c}) = 0.05\)</span>;</li>
<li>we want to find <span class="math inline">\(\mathbb P(D \mid {+})\)</span>.</li>
</ul>
<p>Note also that <span class="math inline">\(D\)</span> (you have the disease) and <span class="math inline">\(D^\mathsf{c}\)</span> (you don’t) make up a partition. Then Theorem <a href="S04-conditional.html#thm:bayes-total">4.4</a> tells us that
<span class="math display">\[  \mathbb P(D \mid {+}) = \frac{\mathbb P(D) \,\mathbb P({+} \mid D)}{\mathbb P(D) \,\mathbb P({+} \mid D)+\mathbb P(D^\mathsf{c}) \,\mathbb P({+} \mid D^\mathsf{c})} . \]</span>
Putting in all the numbers we have, we get
<span class="math display">\[ \mathbb P(D \mid {+}) = \frac{0.02 \times 0.95}{0.02 \times 0.95 + 0.98 \times 0.05} = 0.28 .\]</span></p>
<p>So if you get a positive result on this 95%-accurate test, there’s still only about a 1 in 4 chance you actually have the disease.</p>
<p>Many people find this result surprising. It sometimes helps to put more concrete numbers on things. Suppose 1000 people get tested. On average, we expect about 20 of them to have the disease, and 980 of to not have the disease. Of the 20 with the disease, on average 19 will correctly test positive, while 1 will test negative. Of the 980 without the disease, an average 931 will correctly test negative, but 49 will wrongly test positive. So of the <span class="math inline">\(19+49 = 68\)</span> people with positive tests, only 19 of them actually have the disease, which is 28%.</p>
<p>The key point is that the disease is rare – only 2% of people have it. So even though positive test increases the likelihood you have the disease a lot (it’s about 14 times more likely), it’s not enough to make it a very large probability.</p>
</div>
<div id="summary-034" class="section level2 unnumbered">
<h2>Summary</h2>
<div class="mysummary">
<ul>
<li>Two events are independent if <span class="math inline">\(\mathbb P(A \cap B) = \mathbb P(A)\, \mathbb P(B)\)</span>.</li>
<li>The conditional probability of <span class="math inline">\(B\)</span> given <span class="math inline">\(A\)</span> is <span class="math inline">\({\displaystyle \mathbb P(B \mid A) = \frac{\mathbb P(A \cap B)}{\mathbb P(A)}}\)</span>.</li>
<li>The law of total probability says that if <span class="math inline">\(A_1, A_2, \dots A_n\)</span> is a partition of the sample space, then
<span class="math display">\[ \mathbb P(B) = \sum_{i=1}^n \mathbb P(A_i) \, \mathbb P(B \mid A_i) . \]</span></li>
<li>Bayes’ theorem says that <span class="math inline">\({\displaystyle \mathbb P(A \mid B) = \frac{\mathbb P(A) \,\mathbb P(B \mid A)}{\mathbb P(B)} }\)</span>.</li>
</ul>
</div>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="P2.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="P3.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": null,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["math1710.pdf", "math1710.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
