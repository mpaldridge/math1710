::::: {.myq}
**B1.** For each of the two datasets below, calculate the following summary statistics, or explain why it is not possible to do so: mode; median; mean; number of distinct outcomes; inter-quartile range; and sample variance.

:::: {.subq}
**(a)** Six packets of Skittles are opened together, and the total number of sweets of each colour is:

| **Colour**             | Red | Orange | Yellow | Green  | Purple |
|:----------------------:|:---:|:------:|:------:|:------:|:------:|
| **Number of Skittles** |  67 |   71   |   87   |   74   |   62   |

::: {.myanswers data-latex=""}
*Solution.*
The modal colour is Yellow. The number of distinct outcomes is 5.

It's not possible to calculate the median or the quartiles, because, unlike numerical data, the colours can't be put "in order" from smallest to largest.

It's not possible to calculate the mean or sample variance, as these require us to have numerical data that can be "added up", but this can't be done with colours.
:::
::::

:::: {.subq}
**(b)** Shirt sizes for a university football squad:

| **Colour**             | Xtra Small | Small  | Medium | Large  | Xtra Large |
|:----------------------:|:----------:|:------:|:------:|:------:|:----------:|
| **Number of shirts**   |  0 |   1   |   6   |   4   |   5   |


::: {.myanswers data-latex=""}
*Solution.*
The modal shirt size is medium. The number of distinct outcomes is 4 (we don't quite "Xtra Small", which was not observed in the data).

This time, we can order the data from smallest to largest, even though the data is not numerical. Since $(16 + 1)/2 - 8.5$, the median datapoint is the 8th or 9th datapoints, which are Large.

Since $1 + 0.25(16 - 1) = 4.75$ the lower quartile is the 4th or 5th datapoints, which are Medium. Since $1 + 0.75(16-1) = 12.25$, the upper quartile is the 12th or 13th datapoints, which are Xtra Large. So we can certainly say that the inner quartiles range from Medium to Xtra Large. We could probably also say that the interquartile range is 3 shirt sizes (Medium, Large, Xtra Large).

Again, because the data is not numerical, we can't add it up, so can't calculate a mean or sample variance.

**Group feedback:** Make sure your explanation is clear for why we can't calculate a median for the Skittles data but can for the shirts: they key is whether or not the data can be *ordered*.
:::
::::
:::::

:::: {.myq}
**B2.** A summary statistic is informally said to be "robust" if it typically doesn't change much if a small number of outliers are introduced to a large dataset, or "sensitive" if it often changes a lot when a small number of outliers are introduced. Briefly discuss the robustness or sensitivity of the following summary statistics: **(a)** mode; **(b)** median; **(c)** mean; **(d)** number of distinct outcomes; **(e)** inter-quartile range; and **(f)** sample variance.

::: {.myanswers data-latex=""}
*Solutions.*

**(a)** The mode will typically not change at all if a small number of outliers are introduced, so is robust. (The exception is for data where every observation is likely to be different, so the outliers become "joint modes" along with everything else; but in this case the mode is not a useful statistic in the first place.)

**(b)** The introduction of outliers will typically only change the median a little bit, by shifting it between different nearby values in the "central mass" of the data. In particular, the *size* of the outliers won't make any difference at all (only whether they are "high outliers" above the median or "low outliers" below the median). So the median is robust.

**(c)** The mean can change a lot if outliers are introduced, especially if the outlier is enormously far our from the data. So the mean is sensitive.

**(d)** The number of distinct outcomes will only increase by (at most) 1 for each outlier introduced, so is robust.

**(e)** The interquartile range is robust, for the same reason as the median.

**(f)** The sample variance is sensitive, for the same reason as the mean.

(You might like to think about situations where it's better to use a robust statistic or better to use a sensitive statistic.)

**Group feedback:** I find it helpful to suppose I was studying the net worth of people in my tutorial group, and calculating summary statistics. How would those statistics changed change if Elon Musk (founder of Tesla, net worth roughly $200 billion) joined my tutorial group?

Remember that "robust" and "sensitive" are general descriptions rather than precise mathematical definitions. So it doesn't matter if you disagree with my opinions provided that you give clear and detailed explanations to back up your opinion.
:::
::::

::::: {.myq}
**B3.** Let $\mathbf a = (a_1, a_2, \dots a_n)$ and $\mathbf b = (b_1, b_2, \dots, b_n)$ be two real-valued vectors of the same length. Then the *Cauchy--Schwarz inequality* says that
\[ \left( \sum_{i=1}^n a_i b_i \right)^2 \leq \left( \sum_{i=1}^n a_i^2 \right) \left(\sum_{i=1}^n b_i^2 \right) . \]

:::: {.subq}
**(a)** By making a clever choice of $(a_i)$ and $(b_i)$ in the Cauchy--Schwarz inequality, show that $s_{xy}^2 \leq s_x^2 s_y^2$.
::::

::: {.myanswers data-latex=""}
*Solutions.*
Recalling the formulas for $s_{xy}$, $s_x^2$, and $s_y^2$,
\begin{align*}
s_{xy} &= \frac{1}{n-1} \sum_{i=1}^n (x_i - \bar x)(y_i - \bar y) ,\\
s_{x}^2 &= \frac{1}{n-1} \sum_{i=1}^n (x_i - \bar x)^2 ,\\
s_{y}^2 &= \frac{1}{n-1} \sum_{i=1}^n (y_i - \bar y)^2 ,
\end{align*}
and comparing them with the Cauchy--Schwarz inequality, it looks like taking $a_i = x_i - \bar x$ and $b_i = y_i - \bar y$ might be useful. Making the substitution, we get
\[ \left( \sum_{i=1}^n (x_i - \bar x)(y_i - \bar y) \right)^2 \leq \left( \sum_{i=1}^n (x_i - \bar x)^2 \right) \left(\sum_{i=1}^n (y_i - \bar y)^2 \right) . \]

These are very close to the formulas for $s_{xy}$, $s_x^2$, and $s_y^2$, but are just missing the "$1/(n-1)$"s; what we in fact have is
\[ \left( (n-1) s_{xy} \right)^2 \leq (n-1)s_x^2 \cdot (n-1) s_y^2 .\]
Cancelling $(n-1)^2$ from each side, we have $s_{xy}^2 \leq s_x^2 s_y^2$.
:::

:::: {.subq}
**(b)**
Hence, show that the correlation $r_{xy}$ satisfies $-1 \leq r_{xy} \leq 1$.
::::

::: {.myanswers data-latex=""}
*Solutions.*
Recall the formula for the correlation is
\[ r_{xy} = \frac{s_{xy}}{s_xs_y} . \]
We can make part (a) look a bit like this dividing both sides by $s_x^2 s_y^2$, to get
\[\frac{s_{xy}^2}{s_x^2 s_y^2} \leq 1.   \]
In fact that's the square of the correlation on the left-hand side, so we've shown that $r_{xy}^2 \leq 1$.

Finally, we note that if a number squared is less than or equal to 1, then the number must be between -1 and +1 inclusive. (Numbers bigger than 1 get bigger still when squared; number smalles than -1 become bigger than +1 when squared.) Hence we have shown that $-1 \leq r_{xy} \leq 1$, as required.

**Group feedback:** In part (b) there's a temptation to "square-root both sides of the inequality". But you have to be very careful when you do this -- make sure you are properly accounting for the positive and negative square roots on both side (if necessary), and where that does or doesn't require reversing the inequality. I recommend leaving the square-root operation until the last possible moment of the proof or, perhaps even better, reasoning through words as I did above. 

Remember that you can still attempt part (b) even if you got stuck on part (a).
:::
:::::

:::: {.myq}
**B4.** A researcher wishes to study the effect of mental health on academic achievement. The researcher will collect data on the mental health of a cohort of students by asking them to fill in a questionnaire, and will measure academic achievement via the students' scores on their university exams. Discuss some of the ethical issues associated with the collection, storage, and analysis of this data, and with the publication of the results of the analysis. Are there ways to mitigate these issues?

(It's not necessary to write an essay for this question -- a few short bulletpoints will suffice. There may be an opportunity to discuss these issues in more detail in your tutorial.)

::: {.myanswers data-latex=""}
**Group feedback:** There are no "correct" or "incorrect" answers here, but here are a few things that students in my own tutorials brought up, which may act as a prompt for your own discussions.

* It's important the students/subjects have given their consent for their data to be used this way. It must be "informed consent", where they understand for what purpose the data will be used, how it will be stored, and so on. It must be easy and painless for students to decline to take part.
* Consideration should be given on how to anonymise the data as much as possible -- it's not necessary for those analysing the data to know which questionnaire or which exam result belongs to which student, only that the questionnaire and results can be paired up.
* Even if after data is anonymised, care should be taken about whether the students could be worked out from the data. For example, if only one student did a certain combination of modules, their identity could "leak" that way. Perhaps imprecise data, such as classes rather than exact marks, might help while only slightly reducing the usefulness of the data?
* On one hand, it seems like this data should perhaps be deleted once analysis has been carried out, for the privacy of the students. On the other hand, principles of "open science" suggest that the data should be kept -- and even publically made available -- for other researchers to check the work. There are competing ethical considerations here.
* If correlations are found in the data, care should be taken when publishing the analysis not to wrongly suggest a causation. (Just because X and Y are positively correlated, it doesn't mean that X *causes* Y -- or that Y causes X.)

You can probably think of many other things.
:::
::::