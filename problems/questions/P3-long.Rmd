:::: {.myq}
**B1.** Suppose $A$ and $B$ are independent events. Show that $A$ and $B^\comp$ are also independent events.

::: {.myanswers data-latex=""}
*Solution.* We know that
\[ \mathbb P(A \cap B) = \mathbb P(A) \, \mathbb P(B) , \]
because $A$ and $B$ are independent.
We need to show that $A$ and $B^\comp$ are independent, which means showing that
\[ \mathbb P(A \cap B^\comp) = \mathbb P(A) \, \mathbb P(B^\comp) . \tag{$*$} \]

Note that
\[ A = (A \cap B) \cup (A \cap B^\comp) , \]
and the union is disjoint, so by Axiom 3,
\[ \mathbb P(A) = \mathbb P(A \cap B) + \mathbb P(A \cap B^\comp) . \]
Hence, the left-hand side of $(*)$ is
\begin{align*}
\mathbb P(A \cap B^\comp)
&= \mathbb P(A) - \mathbb P(A \cap B) \\
&= \mathbb P(A) - \mathbb P(A)\,\mathbb P(B) \\
&= \mathbb P(A) \big(1 - \mathbb P(B)\big) ,
\end{align*}
where, in the second line, crucially we used the fact that $A$ and $B$ are independent to replace $\mathbb P(A \cap B)$ by $\mathbb P(A)\,\mathbb P(B)$.

The right-hand side of $(*)$ is
\[\mathbb P(A) \, \mathbb P(B^\comp) = \mathbb P(A) \big(1 - \mathbb P(B)\big) , \]
where we've used the complement rule $\mathbb P(B^\comp) = 1- \mathbb P(B)$.

Hence, we've shown the left- and right-hand sides of $(*)$ are equal, and we are done.
:::
::::

<!--
::::: {.myq}
**B2.** Chloe cycles to work with probability $0.6$ and takes the bus with probability $0.4$. She has noticed that she is late 25% of the time when she takes the bus. Her boss notices that, on average, Chloe is late once per week (that is, one day in every five days).

:::: {.subq}
**(a)** What is the probability that Chloe will be late if she cycles to work?

::: {.myanswers data-latex=""}
*Solution.* 
Let $C$ be the event that Chloe cycles to work and $B$ the event that Chloe takes the bus. Let $L$ be the event that Chloe is late.

* We are told that $\mathbb P(C) = 0.6$ and $\mathbb P(B) = 0.4$. In particular, $B$ and $C$ make up a partition.
* We are told that $\mathbb P(L \mid B) = 0.2$.
* We are told that $\mathbb P(L) = \frac15 = 0.2$.
* We want to find out $\mathbb P(L  \mid C)$.

The law of total probability tells us that
\[  \mathbb P(L) = \mathbb P(C)\,\mathbb P(L \mid C) + \mathbb P(B) \, \mathbb P(L \mid B) . \]
Putting in everything we know, we get
\[ 0.2 = 0.6 \,\mathbb P(L \mid C) + 0.4 \times 0.2 , \]
which rearranges to $\mathbb P(L \mid C) = 0.2$.
:::
::::

:::: {.subq}
**(b)** Chloe is late today, and her boss suspects this is because she took the bus. What is the probability that this guess is correct?

::: {.myanswers data-latex=""}
*Solution.*
This is asking for $\mathbb P(B \mid L)$. We know $\mathbb P(L \mid B) = 0.2$, and want to switch the order of conditioning, so this is a job for Bayes' theorem! We have
\begin{align*}
\mathbb P(B \mid L) &= \frac{\mathbb P(B) \, \mathbb (L \mid B)}{\mathbb P(L)} \\
  &= \frac{0.4 \times 0.2}{0.2} \\
  &= 0.4 .
\end{align*}
:::
::::
:::::
-->

::::: {.myq}
**B2.** You are dealt a hand of 13 cards from a 52-card deck. Let $E_\mathrm{A}, E_\mathrm{K}, E_\mathrm{Q}, E_\mathrm{J}$ respectively be the events that your hand contains the Ace, King, Queen and Jack of Spades.

:::: {.subq}
**(a)** What is $\mathbb P(E_\mathrm{A})$, the probability that your hand contains the Ace of Spades?

::: {.myanswers data-latex=""}
*Solution.* There are 52 cards of which 13 will end up in my hand, so $\mathbb P(E_\mathrm{A}) = \frac{13}{52}$.
:::
::::

:::: {.subq}
**(b)** Explain why $\mathbb P(E_\mathrm{K} \mid E_\mathrm{A}) = \frac{12}{51}$.

::: {.myanswers data-latex=""}
*Solution.* Given I have the Ace of Spades, there are $52 - 1 = 51$ cards left available, of which $13 - 1 = 12$ will end up in my hand, so $\mathbb P(E_\mathrm{K} \mid E_\mathrm{A}) = \frac{12}{51}$.
:::
::::

:::: {.subq}
**(c)** Using the chain rule, calculate the probability that your hand contains all four of the Ace, King, Queen and Jack of Spades.

::: {.myanswers data-latex=""}
*Solution.* Continuing the logic of part (b), we have
\[ \mathbb P(E_\mathrm{Q} \mid E_\mathrm{A} \cap E_\mathrm{K}) = \frac{11}{50} \qquad \mathbb P(E_\mathrm{J} \mid E_\mathrm{A} \cap E_\mathrm{K} \cap E_\mathrm{Q}) = \frac{10}{49} . \]

Using the chain rule,
\begin{align*}
P( E_\mathrm{A} \cap E_\mathrm{K} \cap E_\mathrm{Q} \cap E_\mathrm{J} )
  &= \mathbb P(E_\mathrm{A}) \, \mathbb P(E_\mathrm{K} \mid E_\mathrm{A}) \, \mathbb P(E_\mathrm{Q} \mid E_\mathrm{A} \cap E_\mathrm{K}) \, \mathbb P(E_\mathrm{J} \mid E_\mathrm{A} \cap E_\mathrm{K} \cap E_\mathrm{Q}) \\
  &= \frac{13}{52} \times \frac{12}{51} \times \frac{11}{50} \times \frac{10}{49} = \frac{13 \times 12 \times 11 \times 10}{52 \times 51 \times 50 \times 49} , 
\end{align*}
which is the same as we got in lectures.
:::
::::

:::: {.subq}
**(d)** Check that your answer agrees with the answer we found by classical probability methods in [Example 6.4](L06-classical-ii.html#exm:akqj) in Lecture 6. Which method do you prefer?

::: {.myanswers data-latex=""}
*Solution.* Personally, I slightly prefer this answer -- it seems more obvious how the answer relates to the method, whereas in lectures a lot of terms in a ratio of binomial coefficients "magically" cancelled out. Your mileage may vary.
:::
::::
:::::

<!--
:::: {.myq}
**B3.** Let $\Omega$ be a sample space, let $\mathbb P$ be a probability measure on $\Omega$, and fix an event $B \subset \Omega$ with $\mathbb P(B) > 0$. Show that the conditional probability $\mathbb P( {\cdot} \mid B)$ is also a probability measure on $\Omega$. That is, show that the conditional probability also satisfies the probability axioms:

1. $\mathbb P(A \mid B) \geq 0$ for all events $A \subset \Omega$;
1. $\mathbb P(\Omega \mid B) = 1$;
1. For disjoint events $A_1, A_2, \dots$, we have
\[ \mathbb P(A_1 \cup A_2 \cup \cdots \mid B) = \mathbb P(A_1 \mid B) + \mathbb P(A_2 \mid B) + \cdots . \]

::: {.myanswers data-latex=""}
*Solution.*
For Axiom 1, we have
\[ \mathbb P(A \mid B) = \frac{\mathbb P(A \cap B)}{\mathbb P(B)} . \]
The numerator is non-negative, by Axiom 1 for the probability measure $\mathbb P$, and the denominator is strictly positive, by assumption. Hence, the fraction is non-negative, as required.

For Axiom 2, note that, since $B \subset \Omega$, we have $\Omega \cap B = B$. Hence
\[ \mathbb P(\Omega \mid B) = \frac{\mathbb P(\Omega \cap B)}{\mathbb P(B)} = \frac{\mathbb P(B)}{\mathbb P(B)} = 1 , \]
as required.

For Axiom 3, note that the dsitributive law tells us that
\[ (A1 \cup A_2 \cup \cdots) \cap B = (A_1 \cap B) \cup (A_2 \cap B) \cup \cdots , \]
and the unions remain disjoint. Hence, we have
\begin{align*}
\mathbb P(A_1 &\cup A_2 \cup \cdots \mid B) \\
&= \frac{\mathbb P\big((A_1 \cup A_2 \cup \cdots) \cap B\big)}{\mathbb P(B)} \\
&= \frac{\mathbb P\big((A_1 \cap B) \cup (A_2 \cap B) \cup \dots\big)}{\mathbb P(B)} \\
&= \frac{\mathbb P(A_1 \cap B) + \mathbb P(A_2 \cap B) + \cdots}{\mathbb P(B)} \\
&= \frac{\mathbb P(A_1 \cap B)}{\mathbb P(B)} + \frac{\mathbb P(A_2 \cap B)}{\mathbb P(B)} + \cdots \\
&= \mathbb P(A_1 \mid B) + \mathbb P(A_2 \mid B) + \cdots, 
\end{align*}
where, in the fourth line we used Axiom 3 for the probability measure $\mathbb P(B)$. This proves Axiom 3, and we are done.
:::
::::
-->

::::: {.myq}
**B3.** Soldiers are asked about their use of illegal drugs, using a so-called "randomised survey". Each soldier is handed a deck of three cards, picks one of the three cards at random, and responds according to what the card says. The three cards say:

1. "Say 'Yes.'"
2. "Say 'No.'"
3. "Truthfully answer the question 'Have you taken any illegal drugs in the past 12 months?'"


:::: {.subq}
**(a)** What are some advantages or disadvantages of performing the experiment this way?

::: {.myanswers data-latex=""}
*Solution.* The main advantage is that it seems likely that a soldier might want to lie in answer to a "straight question", given that if their superiors discovered they had taken illegal drugs, there could be very serious consequences. This method allows a certain "plausible deniability": just because the soldier answers "Yes", we cannot know for sure whether they have taken illegal drugs or merely picked the "Yes" card. Thus we might hope to get more honest answers this way. Perhaps you can think of other advantages.

There could be disadvantages. The complicated set-up of the experiment could lead to the subjects (or experimenters) making an error. The scientists good be "lulled into a false sense of security" of thinking they get fully honest answers, when soldiers picking card 3 might still choose to lie. Perhaps you can think of other disadvantages.
:::
::::

:::: {.subq}
**(b)** Suppose that 40% of soldiers respond "Yes". What is the likely proportion of soldiers who have taken illegal drugs in the past 12 months.

::: {.myanswers data-latex=""}
*Solution.*
Let $C_1, C_2, C_3$ be the events that a soldier picks cards 1, 2, or 3 respectively, which have probabilities $\mathbb P(C_1) = \mathbb P(C_2) = \mathbb P(C_3) = \frac13$ and make up a partition. Let $Y$ be the event that the soldier answers yes. We know that $\mathbb P(Y \mid C_1) = 1$, $\mathbb P(Y \mid C_2) = 0$ and $\mathbb P(Y \mid C_3) = \mathbb P(D)$, where $\mathbb P(D)$, which we want to find, is the proportion of soldiers who have taken illegal drugs in the past 12 months. We are also told that $\mathbb P(Y) = 0.4$.

The law of total probability tells us that
\[ \mathbb P(Y) = \mathbb P(C_1)\,\mathbb P(Y \mid C_1) + \mathbb P(C_2)\,\mathbb P(Y \mid C_2) + 
\mathbb P(C_3)\,\mathbb P(Y \mid C_3) .\]
With the information we have, we get
\[ 0.4 = \tfrac13 \times 1 + \tfrac13 \times 0 + \tfrac13 \, p = \tfrac13 + \tfrac13 \,p . \]
Solving this gives $p = \frac15 = 20\%$.
:::
::::

:::: {.subq}
**(c)** If a soldier responds "Yes", what is the probability that the soldier has taken illegal drugs in the past 12 months.

::: {.myanswers data-latex=""}
*Solution.*
This is asking for $\mathbb P(D \mid Y)$. Another one for Bayes theorem:
\[ \mathbb P(D \mid Y) = \frac{\mathbb P(D) \mathbb P(Y \mid D)}{\mathbb P(Y)} . \]
From the question we know that $\mathbb P(Y) = 0.4$. From part (a) we know that $\mathbb P(D) = 0.2$. We also know that $\mathbb P(Y \mid D) = \frac23$, as the soldier will answer Yes is they pick either cards 1 or 3. Hence
\[ \mathbb P(D \mid Y) = \frac{0.2 \times \frac23}{0.4} = \frac13 . \]
:::
::::
:::::

::::: {.myq}
**B4.** A random variable $X_n$ is said to follow the *discrete uniform distribution* on $\{1, 2, \dots, n\}$ if each of the $n$ values in that set $\{1,2,\dots,n\}$ is equally likely.

:::: {.subq}
**(a)** Show that the expectation of $X_n$ is $\mathbb EX_n = \displaystyle\frac{n+1}{2}$.

::: {.myanswers data-latex=""}
*Solution.*
We have $p(x) = \frac1n$ for $x = 1, 2, \dots, n$. So the expectation is
\[ \mathbb EX = \sum_{x=1}^n x\,\frac{1}{n} = \frac{1}{n} \sum_{x = 1}^n x = \frac{1}{n}\, \frac{n(n+1)}{2} = \frac{n+1}{2} . \]
:::
::::

:::: {.subq}
**(b)** Find the variance of $X_n$.

::: {.myanswers data-latex=""}
*Solution.*
It turns out to be much easier to use the computational formual $\Var(X) = \mathbb EX^2 - \mu^2$. First, 
\[ \mathbb EX^2 = \sum_{x=1}^n x^2 \,\frac{1}{n}  = \frac{1}{n} \sum_{x = 1}^n x^2 = \frac{1}{n}\,\frac{n(n+1)(2n+1)}{6} = \frac{(n+1)(2n + 1)}{6} . \]
Then using $\mu = (n+1)/2$ from part (a), we have
\[ \Var(X) =  \frac{(n+1)(2n + 1)}{6} - \left(\frac{n+1}{2}\right)^2 = \frac{(n+1)(4n + 2 - 3n -3)}{12} = \frac{(n+1)(n-1)}{12} = \frac{n^2 - 1}{12}  \]
:::
::::

:::: {.subq}
**(c)** Let $Y$ be a discrete uniform distribution on $b - a + 1$ values $\{a, a+1, a+2, \dots, b-1, b\}$, for integers $a$ and $b$ with $a<b$. Using parts (a) and (b), but without calculating any sums directly, find the expectation and variance of $Y$.

*[**Note:** "$b - a + 1$ values" is correct, but this was wrong earlier.]*

::: {.myanswers data-latex=""}
*Solution.* If we take $n = b - a + 1$, then $Y$ has the same distribution as $X_n + (a-1)$. This is because $x = 1$ maps to $y = 1 + (a-1) = a$; $x = 2$ maps to $y = 2 + (a-1) = a+1$; and so on; up to $x = n$ mapping to $y = n + (a-1) = (b - a + 1) + (a-1) = b$. So the ranges match up perfectly.

Thus we have
\[ \mathbb EY = \mathbb E\big(X_{b-a+1} + (a-1)\big) = \mathbb EX_{b-a+1} + (a-1)= \frac{b - a + 1 +1}{2} + (a-1) = \frac{a + b}{2}  \]
and
\[ \Var(Y) = \Var\big(X_{b-a+1} + (a-1)\big) = \Var(X_{b-a+1}) = \frac{(b - a + 1)^2 - 1}{12} . \]
You can rearrange the variance a bit if you like, but it doesn't really get any nicer.
:::
::::

You may use without proof the standard results
\[ \sum_{x=1}^n x = \frac{n(n+1)}{2} \qquad  \sum_{x=1}^n x^2 = \frac{n(n+1)(2n+1)}{6} . \]
:::::


::::: {.myq}
**B5.** A gambling game works as follows. You keep tossing a fair coin until you first get a Head. If the first Head comes up on the $n$th coin toss, then you win $2^n$ pounds.

:::: {.subq}
**(a)** What is the probability that the first Head is seen on the $n$th toss of the coin?

::: {.myanswers data-latex=""}
*Solution.*
This happens if the first $n-1$ tosses are Tails, with probability $(\frac12)^{n-1}$, them the $n$th toss is Heads, with probability $\frac12$. Altogether, this is $(\frac12)^{n-1}\times \frac12 = (\frac12)^n$.
:::
::::

:::: {.subq}
**(b)** Show that the expected winnings from playing this game are infinite.

::: {.myanswers data-latex=""}
*Solution.*
The expected winnings are
\[ \sum_{n=1}^\infty 2^n \times \mathbb P(\text{first Head on $n$th toss}) = \sum_{n=1}^\infty 2^n \times \big(\tfrac12\big)^n = \sum_{n=1}^\infty 1 = \infty \]
:::
::::

:::: {.subq}
**(c)** The "St Petersburg paradox" refers to the observation that, despite the expected winnings from this game being infinite, few people would be prepared to play this game for, say, £100, and almost no one for £1000. Discuss a few possible "resolutions" to this paradox which could explain why people are unwilling to play this game despite seemingly having infinite expected winnings.

::: {.myanswers data-latex=""}
*Discussion.*
One possibility is:

* The people are being irrational, and in fact *should* play the game for £1000.

but I'm not sure anyone *really* thinks that.

Some other possible explanations include:

* The expectation is only infinite if you really could win an extraordinarily large amount of money. Suppose that the person offering the game only has £$2^{20}$, or just over £1 million. In that case, if the first 20 tosses are all Tails, the opponent gives you all £$2^{20}$ then declares bankruptcy and the game stops. In this more realistic case, your expected winnings are only
\[  \sum_{n=1}^{20} 2^n \times \big(\tfrac12\big)^n + 2^{20} \times \big(\tfrac12\big)^{20} = \sum_{n=1}^{20} 1 + 1 = 21 , \]
or £21; a more reasonable price to pay to play the game.
* The amount of benefit (or "utility") one gets from winning a large amount of money might not be directly proportional to the amount. For example, £200 million might be very nice, but it's not *twice* as nice as £100 million -- after all, what else could you really do with the second £100 million. Perhaps the utility of £$m$ scales more logarithmically than linearly, like $\log_2 m$ in some appropriate "happiness units" In that case, the expected *utility* from the game is
\[ \sum_{n=1}^\infty \log_2(2^n) \times \big(\tfrac12\big)^n = \sum_{n=1}^\infty n \times \big(\tfrac12\big)^n = 2 , \]
happiness units, and you might be willing to pay 2 happiness-units-worth of money to play.
* Normal advice to play games with positive expected winnings only really applies if you can play the game many times (or very similar games). For repeated games, the expected winnings can be interpreted as "the winnings you are likely to get in the long run". For one-off highly unusual games, this doesn't hold, so one needs a different criterion to decide whether to play. (If I was allowed to play this game a million times for £100 a round, but didn't have to settle the money until all one million games had finished, then I would strongly consider playing.)

You can probably come up with other explanations of your own too.
:::
::::
:::::